{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch-basics-part3.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU7G5M10NrPj",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks frm scratch\n",
        "\n",
        "General Neural Network has four phase\n",
        "\n",
        "  * Define NN architechture\n",
        "  * Compute loss\n",
        "  * Backprop\n",
        "  * Update Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWpft3HgODYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9T7NgRDOP03",
        "colab_type": "text"
      },
      "source": [
        "# NN Archiitechture :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WGUEBvQOlZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, (3,3))\n",
        "    self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "    self.fc1 = nn.Linear(16*6*6, 120)\n",
        "    self.fc2 = nn.Linear(120, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "    # print(len(x))\n",
        "    x = torch.flatten(x)\n",
        "    # print(x)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlYlmkydSw14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Net()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dFYI2VgS3UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = list(net.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOFsLYBcVS8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(params))\n",
        "print(params[0].size())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4NS4lQ_VZ0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp = torch.randn(1,1,32,32)\n",
        "out = net(inp)\n",
        "print(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpUU3Ok_asRp",
        "colab_type": "text"
      },
      "source": [
        "# Compute Loss :\n",
        "\n",
        "to compute loss we need to get two inputs :\n",
        "\n",
        "* one actual output and predicted output\n",
        "\n",
        "* then we estimate how far the predicted output is from actual output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6uXfHtXZOWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = net(torch.randn(1,1,32,32))\n",
        "# output = net(input)\n",
        "target = (torch.randn(10))\n",
        "target = torch.flatten(target)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI9SZiSufRub",
        "colab_type": "text"
      },
      "source": [
        "# Backprop\n",
        "\n",
        "to do backpropogation we simply need to call `.backward` on loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxbrnDkcfHST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first we need to erase any accumulated gradients\n",
        "net.zero_grad()\n",
        "print(\"conv1.bias.grad before backprop\")\n",
        "print(net.conv1.bias.grad)\n",
        "# initiate backprop\n",
        "loss.backward()\n",
        "print(\"conv1.bias.grad after backward\")\n",
        "print(net.conv1.bias.grad)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTUVpghwheXO",
        "colab_type": "text"
      },
      "source": [
        "# Update Weights (Gradient Descent)\n",
        "\n",
        "`new_weights = (old_weights - (learning_rate*gradient(old_weights))`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw4tWqDyiE22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gradient descent in pure python\n",
        "learning_rate = 0.01\n",
        "for f in net.parameters():\n",
        "  f.data.sub_(f.grad.data*learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkC5YB-QiIaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# but pytorch has a optimizer function for us to do this\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "input = torch.randn(1,1,32,32)\n",
        "# then in training loop\n",
        "optimizer.zero_grad() # zero grad before updating\n",
        "output = net(input) # output\n",
        "print(output)\n",
        "loss = criterion(output, target) #compute loss\n",
        "print(loss)\n",
        "loss.backward() # backprop\n",
        "optimizer.step() # update weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UueTFjzq2QPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}