{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text classification with character-RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbZccWCvzgjvFFwUVjR85N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGxvzt91PHFH",
        "colab_type": "text"
      },
      "source": [
        "# Text classification using Charecter-*RNN*\n",
        "\n",
        "* Data loading\n",
        "    * letter2tensor\n",
        "    * name2tensor\n",
        "* model defining\n",
        "    * RNN model\n",
        "* training\n",
        "    * RNN from scratch\n",
        "* inference\n",
        "    * inference of a name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upN7JhajQvlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "4023ae17-d794-4e1f-e934-54ea43076c56"
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-10 13:23:29--  https://download.pytorch.org/tutorial/data.zip\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 13.35.163.29, 13.35.163.98, 13.35.163.63, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|13.35.163.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2882130 (2.7M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "\rdata.zip              0%[                    ]       0  --.-KB/s               \rdata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-02-10 13:23:30 (96.5 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
            "\n",
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/eng-fra.txt        \n",
            "   creating: data/names/\n",
            "  inflating: data/names/Arabic.txt   \n",
            "  inflating: data/names/Chinese.txt  \n",
            "  inflating: data/names/Czech.txt    \n",
            "  inflating: data/names/Dutch.txt    \n",
            "  inflating: data/names/English.txt  \n",
            "  inflating: data/names/French.txt   \n",
            "  inflating: data/names/German.txt   \n",
            "  inflating: data/names/Greek.txt    \n",
            "  inflating: data/names/Irish.txt    \n",
            "  inflating: data/names/Italian.txt  \n",
            "  inflating: data/names/Japanese.txt  \n",
            "  inflating: data/names/Korean.txt   \n",
            "  inflating: data/names/Polish.txt   \n",
            "  inflating: data/names/Portuguese.txt  \n",
            "  inflating: data/names/Russian.txt  \n",
            "  inflating: data/names/Scottish.txt  \n",
            "  inflating: data/names/Spanish.txt  \n",
            "  inflating: data/names/Vietnamese.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2LuDlydPLYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import glob\n",
        "import torch.optim as optim\n",
        "import os\n",
        "\n",
        "import string\n",
        "import unicodedata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndmgIGE_ROoN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "e22916ef-90b3-42de-975d-eda370901744"
      },
      "source": [
        "def findfiles(path):\n",
        "    return glob.glob(path)\n",
        "\n",
        "findfiles(\"data/names/*.txt\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data/names/Vietnamese.txt',\n",
              " 'data/names/Greek.txt',\n",
              " 'data/names/Dutch.txt',\n",
              " 'data/names/Japanese.txt',\n",
              " 'data/names/Spanish.txt',\n",
              " 'data/names/Italian.txt',\n",
              " 'data/names/French.txt',\n",
              " 'data/names/Scottish.txt',\n",
              " 'data/names/Portuguese.txt',\n",
              " 'data/names/Polish.txt',\n",
              " 'data/names/Chinese.txt',\n",
              " 'data/names/German.txt',\n",
              " 'data/names/English.txt',\n",
              " 'data/names/Korean.txt',\n",
              " 'data/names/Russian.txt',\n",
              " 'data/names/Czech.txt',\n",
              " 'data/names/Arabic.txt',\n",
              " 'data/names/Irish.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KALeRdVkRYZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initiate all english alphabets and allowed special charecters\n",
        "all_letters = string.ascii_letters + \".,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "# convert text from unicode to ascii\n",
        "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfzlGz10SvJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readlines(filename):\n",
        "    lines = open(filename).read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLxjTjLqTmXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "89cff262-7bd1-4f8a-cd9e-c9b16eb49e2d"
      },
      "source": [
        "# save each language based names in a category dict\n",
        "\n",
        "category = {}\n",
        "\n",
        "for filename in glob.glob(\"data/names/*.txt\"):\n",
        "    category_name = os.path.splitext(os.path.basename(filename))[0]\n",
        "    category[category_name] = readlines(filename)\n",
        "\n",
        "diff_category = category.keys()\n",
        "n_category = len(category.keys())\n",
        "print(diff_category)\n",
        "print(n_category)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['Vietnamese', 'Greek', 'Dutch', 'Japanese', 'Spanish', 'Italian', 'French', 'Scottish', 'Portuguese', 'Polish', 'Chinese', 'German', 'English', 'Korean', 'Russian', 'Czech', 'Arabic', 'Irish'])\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MTSEVaWVPxp",
        "colab_type": "text"
      },
      "source": [
        "# names to tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w58f2CkWUYSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pick a name\n",
        "def name2tensor(name):\n",
        "    #initialse a torch tensor of size all_letters (all alphabets in english)\n",
        "    # vector of (1 X all_letters) dimension.\n",
        "    init_tensor = torch.zeros(len(name), 1, n_letters)\n",
        "    #break into charecter\n",
        "    #if breaked charecter is present replace value to 1 in initialised tensor.\n",
        "    for idx, char in enumerate(name):\n",
        "        init_tensor[idx][0][all_letters.find(char)] = 1\n",
        "    return init_tensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PUUYcwVY-W9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "30278b89-09fb-4c18-dc4b-89feb8e1e4e5"
      },
      "source": [
        "name2tensor('jones').size()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 1, 56])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjKaCEXZalTc",
        "colab_type": "text"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj1FbKWZbgrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.i2h = nn.Linear(input_size+hidden_size, hidden_size)\n",
        "        self.i2o = nn.Linear(input_size+hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        combined = torch.cat((input, hidden), 1)\n",
        "        hidden = self.i2h(combined)\n",
        "        output = self.i2o(combined)\n",
        "        output = self.softmax(output)\n",
        "        return output, hidden\n",
        "\n",
        "    def inithidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS1i_ancotAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_hidden = 128\n",
        "rnn = RNN(input_size=n_letters, hidden_size=n_hidden, output_size=n_category)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQZFl37mwIhD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "050cbc92-8e4b-4a5e-a82b-ea2829f5cdec"
      },
      "source": [
        "rnn"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (i2h): Linear(in_features=184, out_features=128, bias=True)\n",
              "  (i2o): Linear(in_features=184, out_features=18, bias=True)\n",
              "  (softmax): LogSoftmax()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc-2uvE5o5YN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "ce85e57a-e0f0-4c33-b440-dd4c1d2fafc2"
      },
      "source": [
        "input = name2tensor('albert')\n",
        "hidden = torch.zeros(1, n_hidden)\n",
        "\n",
        "output, next_hidden = rnn(input[0], hidden)\n",
        "print(output)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.8669, -2.8953, -2.8668, -2.8744, -2.9019, -2.8706, -2.8947, -3.0067,\n",
            "         -2.8875, -2.8354, -2.9108, -2.8204, -2.8739, -2.8474, -2.9808, -2.8686,\n",
            "         -2.9509, -2.8925]], grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXLa7icGs1OY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_categories = list(category.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xelG4_upsV2M",
        "colab_type": "text"
      },
      "source": [
        "# Training :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bp-s5F8pH8H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5a7ebe9e-1d54-4166-8ed5-e48f7e774c7a"
      },
      "source": [
        "#lets create index for each category\n",
        "def categoryfromoutput(output):\n",
        "    top_n, top_i = output.topk(1)\n",
        "    category_i = top_i[0].item()\n",
        "    return all_categories[category_i], category_i\n",
        "\n",
        "print(categoryfromoutput(output))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('German', 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGLIMEr-tVbC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "a3fa0144-75b6-4a19-b1bf-3ccf597de9b7"
      },
      "source": [
        "import random\n",
        "\n",
        "# get training example\n",
        "def randomchoice(l):\n",
        "    return l[random.randint(0,len(l)-1)]\n",
        "\n",
        "def randomtrainingexample():\n",
        "    select_category = randomchoice(all_categories)\n",
        "    line = randomchoice(category[select_category])\n",
        "    category_tensor = torch.tensor([all_categories.index(category[select_category])], dtype=torch.long)\n",
        "    line_tensor = name2tensor(line)\n",
        "    return select_category, line, category_tensor, line_tensor\n",
        "\n",
        "for i in range(10):\n",
        "    select_category, line, category_tensor, line_tensor = randomtrainingexample()\n",
        "    print(f\"Category : {select_category}, /line= {line}\") "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-0ad58ac24880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mselect_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomtrainingexample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Category : {select_category}, /line= {line}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-0ad58ac24880>\u001b[0m in \u001b[0;36mrandomtrainingexample\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mselect_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_categories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandomchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect_category\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcategory_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_categories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselect_category\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mline_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname2tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mselect_category\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ['Ahn', 'Baik', 'Bang', 'Byon', 'Cha', 'Chang', 'Chi', 'Chin', 'Cho', 'Choe', 'Choi', 'Chong', 'Chou', 'Chu', 'Chun', 'Chung', 'Chweh', 'Gil', 'Gu', 'Gwang', 'Ha', 'Han', 'Ho', 'Hong', 'Hung', 'Hwang', 'Hyun', 'Jang', 'Jeon', 'Jeong', 'Jo', 'Jon', 'Jong', 'Jung', 'Kang', 'Kim', 'Ko', 'Koo', 'Ku', 'Kwak', 'Kwang', 'Lee', 'Li', 'Lim', 'Ma', 'Mo', 'Moon', 'Nam', 'Ngai', 'Noh', 'Oh', 'Pae', 'Pak', 'Park', 'Ra', 'Rhee', 'Rheem', 'Ri', 'Rim', 'Ron', 'Ryom', 'Ryoo', 'Ryu', 'San', 'Seo', 'Seok', 'Shim', 'Shin', 'Shon', 'Si', 'Sin', 'So', 'Son', 'Song', 'Sook', 'Suh', 'Suk', 'Sun', 'Sung', 'Tsai', 'Wang', 'Woo', 'Yang', 'Yeo', 'Yeon', 'Yi', 'Yim', 'Yoo', 'Yoon', 'You', 'Youj', 'Youn', 'Yu', 'Yun'] is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFLqI1T66G7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WS9GE_V31-9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.005"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}